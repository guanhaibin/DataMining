{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAP 5610 - Introduction to Machine Learning <br>Florida International University - Fall 2018\n",
    "## Problem Set #1\n",
    "\n",
    "\n",
    "Pedro J Soto\n",
    "\n",
    "P.ID 1932221\n",
    "\n",
    "psoto004@fiu.edu\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Instructions:\n",
    "Please answer the questions below. Copy this notebook and submit your answers under each problem, inserting cells as needed. You may use a combination of [python](http://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Running%20Code.html), [markdown](http://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html), and [LaTex](http://data-blog.udacity.com/posts/2016/10/latex-primer/) to formulate your responses. Please add your initials to the file name prior to submission. For example, if your name is Juana Perez, you would use the following filename: problem_set_0_JP.ipynb. Prior to completing this assignment, you should brush up on [calculus](https://www.khanacademy.org/math/calculus-home) and [linear algebra](https://www.khanacademy.org/math/linear-algebra)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1 . **[10 points] [Gradients](https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/partial-derivative-and-gradient-articles/a/the-gradient) and [Hessians](https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/quadratic-approximations/a/the-hessian)**  \n",
    "\n",
    "A matrix $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ is considered *symmetric* if $\\mathbf{A}^{T}=\\mathbf{A}$, that is if $\\mathbf{A}_{ij} = \\mathbf{A}_{ji}$ for every $i,j$. The **gradient**, $\\nabla f(x)$, of a function, $f:\\mathbb{R}^n \\rightarrow \\mathbb{R}$, is defined as the *n*-vector of partial derivatives\n",
    "\n",
    "$$\\nabla f(x) = \\begin{bmatrix} \\frac{\\partial}{\\partial x_1}f(x) \\\\ \\vdots \\\\ \\frac{\\partial}{\\partial x_n}f(x) \\end{bmatrix} \\text{ where } \\mathbf{x}=\\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_n \\end{bmatrix}.$$\n",
    "\n",
    "Similarly, the Hessian, $\\nabla^2 f(x)$ of a function, $f:\\mathbb{R}^n \\rightarrow \\mathbb{R}$, is the $n \\times n$ symmetric matrix of second-order partial derivatives, \n",
    "\n",
    "\n",
    "$$\\nabla^2 f(x) = \\begin{bmatrix} \\frac{\\partial^2}{\\partial x^2_1}f(x) & \\frac{\\partial^2}{\\partial x_1 \\partial x_2}f(x) & \\dots & \\frac{\\partial^2}{\\partial x_1 \\partial x_n}f(x) \\\\ \\frac{\\partial^2}{\\partial x_2 \\partial x_1}f(x) & \\frac{\\partial^2}{\\partial x^2_2}f(x) & \\dots & \\frac{\\partial^2}{\\partial x_2 \\partial x_n}f(x) \\\\ \\vdots & \\vdots & \\ddots & \\vdots\\\\ \\frac{\\partial^2}{\\partial x_n \\partial x_1}f(x) & \\frac{\\partial^2}{\\partial x_n \\partial x_2}f(x) & \\dots & \\frac{\\partial}{\\partial x^2_n}f(x) \\end{bmatrix}.$$\n",
    "\n",
    "a) Let $f(x)= \\frac{1}{2}\\mathbf{x}^T\\mathbf{A}\\mathbf{x} + \\mathbf{b}^T\\mathbf{x}$ where $\\mathbf{A}$ is a symmetric matrix and $\\mathbf{b} \\in \\mathbb{R}^n$ is a vector. What is $\\nabla f(x)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Solution 1 a)\n",
    "\n",
    "The derivative of $\\frac{1}{2}x^{T}Ax+b^{t}x $ is equal to \n",
    "\\begin{equation*}\n",
    "    \\nabla f(x) =\\begin{bmatrix}\n",
    "    b_1+\\sum_{j=1}^{n}a_{j,1}x_1     \\\\\n",
    "    b_2+\\sum_{j=1}^{n}a_{j,2}x_2         \\\\\n",
    "    \\vdots \\\\\n",
    "    b_n+\\sum_{j=1}^{n}a_{j,n}x_n        \n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "##### proof:\n",
    "   Let\n",
    "    $h(x)=x^{T}Ax$ \n",
    "   and notice that \n",
    "\\begin{equation*}\n",
    "   Ax =\\begin{bmatrix}\n",
    "   \\sum_{j=1}^{n}a_{1,j}x_j     \\\\\n",
    "    \\sum_{j=1}^{n}a_{2,j}x_j         \\\\\n",
    "    \\vdots \\\\\n",
    "    \\sum_{j=1}^{n}a_{n,j}x_j        \n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "and therefore that \n",
    "\\begin{equation*}\n",
    "    x^{T}Ax= \\sum_{k=1}^{n}\\sum_{j=1}^{n}a_{j,k}x_jx_k=\\sum_{l=1}^{n}a_{l,l}x_l^2+2\\sum_{i<j}a_{i,j}x_ix_j\n",
    "\\end{equation*}\n",
    "where the second equality holds because $a_{i,j}=a_{j,i}$. Finally we notice that \n",
    "\\begin{equation*}\n",
    "    \\frac{\\partial}{\\partial x_k}h(x) = 2a_{k,k}x_k+2\\sum_{j<k}a_{j,k}x_j+ 2\\sum_{k<j}a_{k,j}x_j=2\\sum_{j=1}^{n}a_{k,j}x_j\n",
    "\\end{equation*}\n",
    "Also if we let $g(x)=b^{T}x=\\sum_{i=1}^{n}b_ix_i$ we have that $\\frac{\\partial}{\\partial x_k}g(x) = b_k $. Finally to complete the proof we notice that $f(x)=\\frac{1}{2}h(x)+g(x)$ and therefore that \n",
    "\\begin{equation}\n",
    "    \\frac{\\partial}{\\partial x_k}f(x)=\\frac{\\partial}{\\partial x_k}\\bigg[\\frac{1}{2}h(x)+g(x)\\bigg]= b_k+\\sum_{j=1}^{n}a_{k,j}x_j\n",
    "\\end{equation}\n",
    "which is the $k^{th}$ component of $\\nabla f$ and therefore the proof is complete. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Let $f(x)=g(h(x))$, where $g: \\mathbb{R} \\rightarrow \\mathbb{R}$ is differentiable and $h: \\mathbb{R}^n \\rightarrow \\mathbb{R}$ is differentiable. What is $\\nabla f(x)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Solution 1 b)\n",
    "The derivative of $f(x)=g(h(x))$ is equal to  \n",
    "\\begin{equation}\n",
    "    \\nabla f(x) = \\frac{d[g(h(x))]}{d[h(x)]}\\nabla h(x)\n",
    "\\end{equation}\n",
    "\n",
    "We can show this two ways:\n",
    "\n",
    "\n",
    "1.by using the generalized chain rule which says that if $[J_x(h)]_{i,j}=\\frac{\\partial}{\\partial x_j}h_i(x)$ is the derivative of $h$ and $[J_x(g)]_{i,j}=\\frac{\\partial}{\\partial x_j}g_i(x)$ is the derivative of $g$ then the derivative of $g(h(x))$ is equal to $J_x(g\\circ h)=J_{h(x)}(g\\circ h)J_x(h)$ where we are performing matrix multiplication \n",
    "\n",
    "\n",
    "2.we can directly compute $\\nabla f$ and effectively prove the chain rule for this special case\n",
    "\n",
    "##### Proof:\n",
    "By definition $(\\nabla f)_k =  \\frac{\\partial}{\\partial x_k}f(x) $ and therefore by the chain rule from calculus 1 we have that \n",
    "\\begin{equation*}\n",
    "   (\\nabla f)_k = \\frac{\\partial}{\\partial x_k}f(x) = \\frac{\\partial}{\\partial x_k}g(h(x)) = \\frac{d[g(h(x))]}{d h(x)}\\frac{\\partial h(x)}{\\partial x_k}\n",
    "\\end{equation*}\n",
    "which gives us that $ \\nabla f(x) = \\frac{d[g(h(x))]}{d[h(x)]}\\nabla h(x)$ as was needed to be shown. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Let $f(x)= \\frac{1}{2}\\mathbf{x}^T\\mathbf{A}\\mathbf{x} + \\mathbf{b}^T\\mathbf{x}$ where $\\mathbf{A}$ is a symmetric matrix and $\\mathbf{b} \\in \\mathbb{R}^n$ is a vector. What is $\\nabla^2 f(x)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Solution 1 c)\n",
    "We have that $\\nabla^2 f(x) = A $\n",
    "\n",
    "In equation (1) in section (a) of the 1$^{st}$ problem in this homework we derived the following equality \n",
    "\\begin{equation*}\n",
    "    \\frac{\\partial}{\\partial x_k}f(x)=b_k+\\sum_{j=1}^{n}a_{k,j}x_j\n",
    "\\end{equation*}\n",
    "which gives us that \n",
    "\\begin{equation*}\n",
    "   [\\nabla^2 f(x)]_{l,k}=\\frac{\\partial}{\\partial x_l} \\frac{\\partial}{\\partial x_k}f(x)=a_{k,l}=a_{l,k}\n",
    "\\end{equation*}\n",
    "which completes the proof."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Let $f(x)=g(a^Tx)$, where $g: \\mathbb{R} \\rightarrow \\mathbb{R}$ is continuously differentiable and $a \\in \\mathbb{R}^n$ is a vector. What are $\\nabla f(x)$ and $\\nabla^2 f(x)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Solution 1 d)\n",
    "The derivative of $f=g(\\mathbf{a}^{T}\\mathbf{x})$ is equal to \n",
    "\\begin{equation*}\n",
    "    \\nabla f(\\mathbf{x}) = \\frac{d[g(\\mathbf{a}^{T}\\mathbf{x})]}{d[\\mathbf{a}^{T}\\mathbf{x}]} \\mathbf{a}\n",
    "\\end{equation*}\n",
    "\n",
    "##### Proof:\n",
    "In equation (2) in section (b) of the 1$^{st}$ problem in this homework we derived the following equality \n",
    "\\begin{equation*}\n",
    "    \\nabla f(x) = \\frac{d[g(h(x))]}{d[h(x)]}\\nabla h(x) \n",
    "\\end{equation*}\n",
    "and therefore by setting $h(\\mathbf{x}) = \\mathbf{a}^{T}\\mathbf{x} = \\sum_{i=1}^na_ix_i$ and noticing that \n",
    "\\begin{equation*}\n",
    "    \\nabla h(\\mathbf{x}) =\n",
    "    \\begin{bmatrix}\n",
    "    \\frac{\\partial h(\\mathbf{x})}{\\partial x_k}    \\\\\n",
    "   \\frac{\\partial h(\\mathbf{x})}{\\partial x_k}        \\\\\n",
    "    \\vdots \\\\\n",
    "   \\frac{\\partial h(\\mathbf{x})}{\\partial x_k}       \n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "  a_1   \\\\\n",
    "   a_2     \\\\\n",
    "    \\vdots \\\\\n",
    "   a_n      \n",
    "\\end{bmatrix}\n",
    "=\\mathbf{a}\n",
    "\\end{equation*}\n",
    "we get that $\\nabla f(\\mathbf{x}) = \\frac{d[g(\\mathbf{a}^{T}\\mathbf{x})]}{d[\\mathbf{a}^{T}\\mathbf{x}]} \\mathbf{a}$ as was needed to be shown. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2. **[10 points] [Eigen Vectors, eigenvalues, and the spectral theorem](https://www.khanacademy.org/math/linear-algebra/alternate-bases#eigen-everything)**  \n",
    "\n",
    "The eigen values of an nxn matrix $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ are the roots of the characteristic polynomial $p_A(\\lambda)= \\text{det}(\\lambda \\mathbf{I} - \\mathbf{A})$, which may be in general complex. They are also defined as the values $\\lambda \\in \\mathbb{C}$ for which there exists a vector $\\mathbf{x} \\in \\mathbb{C}^n$ to the n  such that $\\mathbf{A}\\mathbf{x} = \\lambda \\mathbf{x}$. We call such a pair $(\\mathbf{x}, \\lambda)$, the *eigenvector*, *eigenvalue* pair. Here we use the notation $\\text{diag}(\\lambda_1,\\dots,\\lambda_n)$ to denote the diagonal matrix with diagonal entries $\\lambda_1, \\dots, \\lambda_n$ that is,\n",
    "\n",
    "$$\\text{diag}(\\lambda_1,\\dots,\\lambda_n) = \\begin{bmatrix} \n",
    "\\lambda_1 & 0 & 0 & \\dots & 0 \\\\\n",
    "0 & \\lambda_2 & 0 & \\dots & 0 \\\\\n",
    "0 & 0 & \\lambda_3 & \\dots & 0 \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "0 & 0 & 0 & \\dots & \\lambda_n\n",
    "\\end{bmatrix}.$$\n",
    "\n",
    "a) Suppose that the matrix $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ is diagonalizable, that is, $\\mathbf{A} = \\mathbf{T} \\mathbf{\\Lambda} \\mathbf{T}^{-1}$ for an invertible matrix $\\mathbf{T} \\in \\mathbb{R}^{n \\times n}$, where $\\mathbf{\\Lambda} = \\text{diag}(\\lambda_1, \\dots, \\lambda_n)$ is diagonal. Use the notation $t^{(i)}$ for the columns of $\\mathbf{T}$, so that $\\mathbf{T} = \\begin{bmatrix} t^{(1)} & \\dots & t^{(n)}\\end{bmatrix}$, where $t^{(i)} \\in \\mathbb{R}^n$. Show that $\\mathbf{A}t^{(i)} = \\lambda_i t^{(i)}$ so that the eigenvalue/eigenvector pairs of $\\mathbf{A}$ are $(t^{(i)}, \\lambda_i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Solution 2 a)\n",
    "\n",
    "The crux of the proof lies in proving the fact that $T^{-1}$ is the transition matrix from $\\{\\mathbf{t}_1,...,\\mathbf{t}_n\\}$ to $\\{\\mathbf{e}_1,...,\\mathbf{e}_n\\}$ and that $T$ is the transition matrix from $\\{\\mathbf{e}_1,...,\\mathbf{e}_n\\}$ to $\\{\\mathbf{t}_1,...,\\mathbf{t}_n\\}$ so that $T^{-1}(\\mathbf{t}_i)=\\mathbf{e}_i$ and that $T(\\mathbf{e}_i)=\\mathbf{t}_i$  which gives us that $T\\Lambda T^{-1}t^{(i)}= T\\Lambda \\mathbf{e}_i = \\lambda_i T \\mathbf{e}_i  = \\lambda_i t^{(i)} $. We now give the full proof for completeness. \n",
    "##### Proof:\n",
    "Notice that because $t^{(i)}= \\begin{bmatrix}\n",
    "  t_{1,i}  \\\\\n",
    "   t_{2,i}    \\\\\n",
    "    \\vdots \\\\\n",
    "   t_{n,i}      \n",
    "\\end{bmatrix}$ and $[T^{-1}T]_{k,i} = \\sum_{l=1}^n t_{k,l}^{-1}t_{l,i} = \\delta_{k,i}$ by definition $\\bigg($where $ \\delta_{k,i} =\n",
    " \\left\\{\n",
    "\\begin{array}{ll}\n",
    "1 & \\textbf{if }  k=i \\\\\n",
    "0 & \\textbf{if } k \\neq i \\\\\n",
    "\\end{array} \n",
    "\\right.\\bigg)$ we therefore have that \n",
    "\\begin{equation*}\n",
    "    T^{-1}t^{(i)} = \\begin{bmatrix}\n",
    "  \\sum_{l=1}^n t_{1,l}^{-1}t_{l,i}  \\\\\n",
    "  \\sum_{l=1}^n t_{2,l}^{-1}t_{l,i}    \\\\\n",
    "    \\vdots \\\\\n",
    "   \\sum_{l=1}^n t_{n,l}^{-1}t_{l,i}      \n",
    "\\end{bmatrix} = \n",
    "  \\begin{bmatrix}\n",
    "  [T^{-1}T]_{1,i} \\\\\n",
    "  [T^{-1}T]_{2,i}    \\\\\n",
    "    \\vdots \\\\\n",
    "   [T^{-1}T]_{n,i}     \n",
    "\\end{bmatrix}= \n",
    "  \\begin{bmatrix}\n",
    "  \\delta_{1,i} \\\\\n",
    "  \\delta_{2,i}    \\\\\n",
    "    \\vdots \\\\\n",
    "   \\delta_{n,i}     \n",
    "\\end{bmatrix}\n",
    "=\\mathbf{e}_i\n",
    "\\end{equation*}\n",
    "which in turn gives us that $\\Lambda T^{-1}t^{(i)} = \\lambda_i \\mathbf{e}_i $ from which we finally derive \n",
    "\\begin{equation*}\n",
    "    T\\Lambda T^{-1}t^{(i)}  = T \\lambda_i \\mathbf{e}_i = \\lambda_i T \\mathbf{e}_i  = \\lambda_i \n",
    "  \\begin{bmatrix}\n",
    "  \\sum_{l=1}^n t_{1,l}\\delta_{l,i} \\\\\n",
    "  \\sum_{l=1}^n t_{2,l}\\delta_{l,i}    \\\\\n",
    "    \\vdots \\\\\n",
    "   \\sum_{l=1}^n t_{n,l} \\delta_{l,i}     \n",
    "\\end{bmatrix}\n",
    "=\\lambda_i \n",
    "  \\begin{bmatrix}\n",
    "  t_{1,i}  \\\\\n",
    "   t_{2,i}    \\\\\n",
    "    \\vdots \\\\\n",
    "   t_{n,i}      \n",
    "\\end{bmatrix} = \\lambda_i t^{(i)}\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matrix $\\mathbf{U} \\in \\mathbb{R}^{n \\times n}$ is *orthogonal* if $\\mathbf{U}^T\\mathbf{U}=\\mathbf{I}$. The spectral theorem states that if $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ is symmetric, that is $\\mathbf{A} = \\mathbf{A}^T$, then $\\mathbf{A}$ is *diagonalizable by a real orthogonal matrix*. In other words, there are a diagonal matrix $\\mathbf{\\Lambda} \\in \\mathbb{R}^{n \\times n}$ and orthogonal matrix $\\mathbf{U} \\in \\mathbb{R}^{n \\times n}$ such that $\\mathbf{U}^T\\mathbf{A}\\mathbf{U} = \\mathbf{\\Lambda}$, or equivalently,\n",
    "$$\\mathbf{A}=\\mathbf{U}\\mathbf{\\Lambda} \\mathbf{U}^T.$$\n",
    "\n",
    "Let $\\lambda_i = \\lambda_i(\\mathbf{A})$ denote the $i$th eigenvalue of $\\mathbf{A}$.\n",
    "\n",
    "b) Let $\\mathbf{A}$ be symmetric. Show that if $\\mathbf{U} = \\begin{bmatrix} u^{(1)} & \\dots & u^{(n)} \\end{bmatrix}$ is orthogonal, where $u^{(i)} \\in \\mathbb{R}^n$ and $\\mathbf{A}=\\mathbf{U}\\mathbf{\\Lambda} \\mathbf{U}^T$, then $u^{(i)}$ is an eigenvector of $\\mathbf{A}$ and $\\mathbf{A}u^{(i)} = \\lambda_i u^{(i)}$, where $\\mathbf{\\Lambda} = \\text{diag}(\\lambda_1, \\dots, \\lambda_n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Solution 2 b)\n",
    "If we let $T=U$ and let $t^{(i)}=u^{(i)}$ and we notice that $U^TT=U^TU=I$  we then have that $T^{-1}=U^T$ and therefore by the proof from the previous section (part (a) of problem \\# 2) we that $U\\Lambda U^{T}u^{(i)}=T\\Lambda T^{-1}t^{(i)}= T\\Lambda \\mathbf{e}_i = \\lambda_i T \\mathbf{e}_i  = \\lambda_i t^{(i)} =   \\lambda_iu^{(i)}$ by an identical argument. We give the full proof for completeness. \n",
    "\n",
    "##### Proof:\n",
    "Because $u^{(i)}= \\begin{bmatrix}\n",
    "  u_{1,i}  \\\\\n",
    "   u_{2,i}    \\\\\n",
    "    \\vdots \\\\\n",
    "   u_{n,i}      \n",
    "\\end{bmatrix}$ and $[I]_{k,i}=[U^{T}U]_{k,i} = \\sum_{l=1}^n u_{k,l}^{T}u_{l,i}=\\delta_{k,i}$ by definition we therefore have that \n",
    "\\begin{equation*}\n",
    "    U^{T}u^{(i)} = \\begin{bmatrix}\n",
    "  \\sum_{l=1}^n u_{1,l}^{T}u_{l,i}  \\\\\n",
    "  \\sum_{l=1}^n u_{2,l}^{T}u_{l,i}    \\\\\n",
    "    \\vdots \\\\\n",
    "   \\sum_{l=1}^n u_{n,l}^{T}u_{l,i}      \n",
    "\\end{bmatrix} = \n",
    "  \\begin{bmatrix}\n",
    "  [U^{T}U]_{1,i} \\\\\n",
    "  [U^{T}U]_{2,i}    \\\\\n",
    "    \\vdots \\\\\n",
    "   [U^{T}U]_{n,i}     \n",
    "\\end{bmatrix}= \n",
    "  \\begin{bmatrix}\n",
    "  \\delta_{1,i} \\\\\n",
    "  \\delta_{2,i}    \\\\\n",
    "    \\vdots \\\\\n",
    "   \\delta_{n,i}     \n",
    "\\end{bmatrix}\n",
    "=\\mathbf{e}_i\n",
    "\\end{equation*}\n",
    "which in turn gives us that $\\Lambda U^{T}u^{(i)} = \\lambda_i \\mathbf{e}_i $ from which we finally derive \n",
    "\\begin{equation*}\n",
    "    U\\Lambda U^{T}u^{(i)}  = U \\lambda_i \\mathbf{e}_i = \\lambda_i U \\mathbf{e}_i  = \\lambda_i \n",
    "  \\begin{bmatrix}\n",
    "  \\sum_{l=1}^n u_{1,l}\\delta_{l,i} \\\\\n",
    "  \\sum_{l=1}^n u_{2,l}\\delta_{l,i}    \\\\\n",
    "    \\vdots \\\\\n",
    "   \\sum_{l=1}^n u_{n,l} \\delta_{l,i}     \n",
    "\\end{bmatrix}\n",
    "=\\lambda_i \n",
    "  \\begin{bmatrix}\n",
    "  u_{1,i}  \\\\\n",
    "   u_{2,i}    \\\\\n",
    "    \\vdots \\\\\n",
    "   u_{n,i}      \n",
    "\\end{bmatrix} = \\lambda_i u^{(i)}\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Show that if $\\mathbf{A}$ is positive semi-definite, then $\\lambda_i(\\mathbf{A}) \\geq 0$ for each $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Solution 2 c)\n",
    "##### Proof:\n",
    "Let $t^{(i)} \\neq 0 $ be an eigenvector corresponding to the eigenvalue $\\lambda_i$ of $A$ and notice that \n",
    "\\begin{equation*}\n",
    "    (\\forall x) (x^TAx \\geq 0)\n",
    "\\end{equation*}\n",
    "implies that \n",
    "\\begin{equation*}\n",
    "    (t^{(i)})^TAt^{(i)} =   (t^{(i)})^T\\lambda_it^{(i)} = \\lambda_i \\sum_{l=1}^n (t^{(i)}_l)^2 = \\lambda_i |t^{(i)}|^2 \\geq 0\n",
    "\\end{equation*}\n",
    "finally notice that \n",
    "\\begin{equation*}\n",
    "    t^{(i)} \\neq 0 \\implies |t^{(i)}|^2 > 0 \n",
    "\\end{equation*}\n",
    "which gives us that \n",
    "\\begin{equation*}\n",
    "    \\lambda_i < 0 \\implies \\lambda_i |t^{(i)}|^2  = (t^{(i)})^TAt^{(i)} <  0\n",
    "\\end{equation*}\n",
    "which would contradict the semi-positive definiteness of $A$. Therefore $\\lambda_i \\geq 0 $ as was needed to be shown. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 3. **[10 points] [Positive definite matrices](https://cedar.buffalo.edu/~srihari/CSE574/Chap1/LinearAlgebra.pdf)**  \n",
    "\n",
    "A matrix $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ is *positive semi-definite* (PSD), denoted $\\mathbf{A} \\succeq 0$, if $\\mathbf{A} = \\mathbf{A}^T$ and $\\mathbf{x}^T\\mathbf{A}\\mathbf{x} \\geq 0$ for all $\\mathbf{x} \\in \\mathbb{R}^n$. A matrix $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ is *positive definite*, denoted $\\mathbf{A} \\succ 0$, if $\\mathbf{A} = \\mathbf{A}^T$ and $\\mathbf{x}^T\\mathbf{A}\\mathbf{x} \\gt 0$ for all $\\mathbf{x} \\neq 0$, that is, all non-zero vectors $\\mathbf{x}$. In simple terms, a matrix $\\mathbf{A}$ whose eigenvalues are all positive is called *positive definite*. A matrix $\\mathbf{A}$ whose eigenvalues are all positive or zero is called positive semi-definite. If the eigenvalues of a matrix $\\mathbf{A}$ are negative, then the matrix is said to be negative definite.\n",
    "\n",
    "a)Recall the identity matrix, $\\mathbf{I}_n$, is a matrix of size $n \\times n$ with ones along the diagonal. For example, $\\mathbf{I}_3$ is\n",
    "\n",
    "$$\\mathbf{I}_3 = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1\\end{bmatrix}$$\n",
    "\n",
    "Show that the identity matrix $\\mathbf{I}_n$ is positive definite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Solution 3 a)\n",
    "##### Proof:\n",
    "\n",
    "$I$ is positive definite because $\\mathbf{x}^TI\\mathbf{x} = (\\mathbf{x} \\cdot \\mathbf{x}) = |\\mathbf{x}|^2 \\geq 0 $. As a matter of fact $A$ is positive definite because  $(\\mathbf{x} \\cdot \\mathbf{x}) = 0 \\Longleftrightarrow \\mathbf{x} =0  $. We give a proof for completeness. \n",
    "\n",
    "\n",
    "We know that \n",
    "\\begin{equation*}\n",
    "    \\mathbf{x}^TI\\mathbf{x} = \n",
    "   x^T\\begin{bmatrix}\n",
    "   \\sum_{j=1}^{n}\\delta_{1,j}x_j     \\\\\n",
    "    \\sum_{j=1}^{n}\\delta_{2,j}x_j         \\\\\n",
    "    \\vdots \\\\\n",
    "    \\sum_{j=1}^{n}\\delta_{n,j}x_j        \n",
    "\\end{bmatrix} = \\sum_{k=1}^{n}\\sum_{j=1}^{n}\\delta_{j,k}x_jx_k = \\sum_{j=1}^{n}x_j^2 = (\\mathbf{x} \\cdot \\mathbf{x}) = |\\mathbf{x}|^2 \\geq 0\n",
    "\\end{equation*}\n",
    "which completes the proof. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Let $\\mathbf{z} \\in \\mathbb{R}^n$ be an $n$-vector. Show that $\\mathbf{A} = \\mathbf{z}\\mathbf{z}^T$ is positive semi-definite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Solution 3 b)\n",
    "##### Proof:\n",
    "\n",
    "The proof for this statement is almost identical to the one for the previous statement(part (a) of problem 3) because we have that $\\mathbf{x}^TA\\mathbf{x} =  (\\mathbf{z} \\cdot \\mathbf{x})^2 \\geq 0$. We give the full proof for completeness. \n",
    "\n",
    "Notice that \n",
    "\\begin{equation*}\n",
    "    A=\\mathbf{z}\\mathbf{z}^T = \\begin{bmatrix}\n",
    "  z_{1}  \\\\\n",
    "  z_{2}    \\\\\n",
    "    \\vdots \\\\\n",
    "  z_{n}      \n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "  z_{1}  &\n",
    "  z_{2}   &\n",
    "    ... &\n",
    "  z_{n} \\\\       \n",
    "\\end{bmatrix} = A=\\mathbf{z}\\mathbf{z}^T = \\begin{bmatrix}\n",
    "  z_{1}z_{1}& z_1z_2& ... & z_1z_n  \\\\\n",
    "  z_{2} z_1 & z_2z_2 & ...   & \\vdots   \\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "  z_{n} & ... & & z_nz_n       \n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "therefore we have that \n",
    "\\begin{equation*}\n",
    "    \\mathbf{x}^TA\\mathbf{x} = \\sum_{i = 1}^n \\sum_{j=1}^na_{i,j}x_ix_j=\\sum_{i = 1}^n \\sum_{j=1}^nz_iz_jx_ix_j = \\sum_{i = 1}^n x_iz_i \\sum_{j=1}^nx_jz_j\n",
    "\\end{equation*}\n",
    "\\begin{equation*}\n",
    "    = \\bigg(\\sum_{i = 1}^n z_ix_i\\bigg)\\bigg(\\sum_{j = 1}^n z_jx_j\\bigg) = (\\mathbf{z} \\cdot \\mathbf{x})(\\mathbf{z} \\cdot \\mathbf{x})=(\\mathbf{z} \\cdot \\mathbf{x})^2 \\geq 0 \n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Let $\\mathbf{z} \\in \\mathbb{R}^n$ be a *non-zero* $n$-vector. Let $\\mathbf{A} = \\mathbf{z}\\mathbf{z}^T$. What is the [nullspace](https://www.khanacademy.org/math/linear-algebra/vectors-and-spaces/null-column-space/v/null-space-2-calculating-the-null-space-of-a-matrix) of $\\mathbf{A}$? What is the [rank](https://www.khanacademy.org/math/linear-algebra/vectors-and-spaces/null-column-space/v/dimension-of-the-column-space-or-rank) of $\\mathbf{A}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Solution 3 c)\n",
    "##### Proof:\n",
    "\n",
    "The nullspace of $A= \\mathbf{z} \\mathbf{z}^T$ is equal to the hyperplane defined by the equation $z_1x_1+...+z_nx_n = (\\mathbf{z} \\cdot \\mathbf{x}) = 0$ which has dimension $n-1$ and therefore the rank of the function is equal to 1 by the rank-nullity theorem. We give a full proof (without any advanced theorems) for completeness.  \n",
    "\n",
    "Notice that \\begin{equation*}\n",
    "   A\\mathbf{x} = \\mathbf{z} \\mathbf{z}^T\\mathbf{x} = (\\mathbf{z} \\cdot \\mathbf{x}) \\mathbf{z}\n",
    "\\end{equation*} \n",
    "and therefore that the image of the function $f(\\mathbf{x}) = A\\mathbf{x} $ is the line defined by $\\mathbf{z}$. Because the definition of the rank is the dimension of the image of $A$ we have that the rank is 1 (if one uses the column space definition of the rank notice that $A=\\begin{bmatrix}\n",
    "  z_{1}\\mathbf{z}  &\n",
    "  z_{2}\\mathbf{z}   &\n",
    "    ... &\n",
    "  z_{n}\\mathbf{z} \\\\       \n",
    "\\end{bmatrix}$ and therefore the column space is equal to $\\textrm{col}(A) = $span$\\{\\mathbf{z}\\}$ which has dimension 1). The null-space is the set of $\\mathbf{x}$ such that $A\\mathbf{x} = (\\mathbf{z} \\cdot \\mathbf{x}) \\mathbf{z} = 0 $. But notice that \n",
    "\\begin{equation*}\n",
    "    A\\mathbf{x}=(\\mathbf{z} \\cdot \\mathbf{x}) \\mathbf{z} = 0 \\Longrightarrow z_1x_1+...+z_nx_n = 0\n",
    "\\end{equation*}\n",
    "which is the equation of a hyper-plane in $n$ dimensions. To see why this is true without loss of generality let $z_1 \\neq 0$ notice that if $x_2=a_2,x_2=a_3,...,x_n=a_n$ we have that \n",
    "\\begin{equation*}\n",
    "    A\\mathbf{x} = 0  \\implies z_1x_1+...+z_nx_n = 0 \\implies x_1= \\frac{z_2}{z_1}a_2+...+\\frac{z_n}{z_1}a_n\n",
    "\\end{equation*}\n",
    "which implies that \n",
    "\\begin{equation*}\n",
    "    \\textrm{Null}(A) = \\{v \\in \\mathbb{R}^n \\ | \\ (\\exists (a_2,...,a_n) \\in \\mathbb{R}^{n-1} )v =a_2 \\begin{bmatrix}\n",
    "  \\frac{z_2}{z_1}  \\\\\n",
    "  1    \\\\\n",
    "  0     \\\\\n",
    "    \\vdots \\\\\n",
    " 0     \n",
    "\\end{bmatrix}  + a_3 \\begin{bmatrix}\n",
    "  \\frac{z_3}{z_1}  \\\\\n",
    "  0    \\\\\n",
    "  1     \\\\\n",
    "    \\vdots \\\\\n",
    " 0     \n",
    "\\end{bmatrix}  + ... + a_n \\begin{bmatrix}\n",
    "  \\frac{z_n}{z_1}  \\\\\n",
    "  0    \\\\\n",
    "  0     \\\\\n",
    "    \\vdots \\\\\n",
    " 1     \n",
    "\\end{bmatrix} \\}\n",
    "\\end{equation*}\n",
    "which is a linear subspace of $\\mathbb{R}^{n}$ of dimension ${n-1}$ (i.e. a hyperplane)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Let $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ be positvie semi-definite and $\\mathbf{B} \\in \\mathbb{R}^{m \\times n}$ be arbitrary, where $m,n \\in \\mathbb{N}$. Is $\\mathbf{B}\\mathbf{A}\\mathbf{B}^T$ PSD? If so, prove it. If not, give a counter example with explicit $\\mathbf{A},\\mathbf{B}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Solution 3 d)\n",
    "\n",
    "\n",
    "Yes. If $A \\in \\mathbb{R}^{n \\times n }$ is positive semi-definite and $B \\in \\mathbb{R}^{m \\times n }$ is an arbitrary matrix then we have that $BAB^T$ is positive semi-definite. The crux of the proof lies in noticing that $ \\mathbf{u} = B^T\\mathbf{x} = (\\mathbf{x}^TB)^T $ and therefore that $\\mathbf{x}^TBAB^T\\mathbf{x} = \\mathbf{u}A\\mathbf{u}^T \\geq 0$ which then gives us the result. \n",
    "\n",
    "##### Proof:\n",
    "\n",
    "Let $x \\in \\mathbb{R}^{n} $ be an arbitrary vector and notice that if we let $ \\mathbf{u} = B^T\\mathbf{x}$, then we have that \n",
    "\\begin{equation*}\n",
    "    [ \\mathbf{u}]_{1,k} = [B^T\\mathbf{x}]_{1,k} =\\sum_{i=1}^{m}b^T_{k,i}x_i =\\sum_{i=1}^{m}x_ib_{i,k}  =  [\\mathbf{x}^TB ]_{k,1} =[\\mathbf{u}^T]_{k,1}\n",
    "\\end{equation*}\n",
    "and therefore $B^T\\mathbf{x} = (\\mathbf{x}^TB)^T $. Also because $\\mathbf{y}^TA\\mathbf{y}\\geq 0$ for any $\\mathbf{y}$ we have that \n",
    "\\begin{equation*}\n",
    "    \\mathbf{x}^TBAB^T\\mathbf{x} = \\mathbf{u}^TA\\mathbf{u} \\geq 0\n",
    "\\end{equation*}\n",
    "which gives us that $BAB^T$ is positive semi-definite as was needed to be shown. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
